import datetime
import json # Not strictly needed for this script, but good practice if it were more complex

def generate_integration_plan_report():
    report_lines = []
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    report_lines.append(f"# crewAI SQLite Integration & Refactoring Plan")
    report_lines.append(f"Generated: {timestamp}\n")
    report_lines.append("This document outlines a plan to adapt `crewai` for improved Termux compatibility, focusing on replacing `chromadb` with a user-provided SQLite-based vector storage solution and addressing the `onnxruntime` dependency.\n")

    # --- Section 1: ChromaDB Analysis and SQLite Integration ---
    report_lines.append("## 1. Integrating SQLite-based Vector Storage (Alternative to ChromaDB)\n")
    report_lines.append("The user cannot install `chromadb` on their Termux environment and has provided a Python `Database` class using SQLite and NumPy for basic vector storage and similarity search. This section details how `crewai` currently uses `chromadb` and proposes a strategy to integrate the user's solution.\n")

    report_lines.append("### 1.1. Current `chromadb` Usage in `crewai`")
    report_lines.append("Analysis of `src/crewai/knowledge/storage/knowledge_storage.py`, `src/crewai/memory/storage/rag_storage.py`, and `src/crewai/utilities/embedding_configurator.py` reveals the following `chromadb` API usage:")
    report_lines.append("- **Client:** `chromadb.PersistentClient(path=...)` is used to create on-disk vector stores.")
    report_lines.append("- **Collections:** `app.get_or_create_collection(name=..., embedding_function=...)`, `app.get_collection(...)`, `app.create_collection(...)` are used. Collections are named based on knowledge base names or memory types.")
    report_lines.append("- **Embedding Functions:** `EmbeddingConfigurator` is used to supply `chromadb` with an appropriate `EmbeddingFunction` (e.g., OpenAI, Ollama), which `chromadb` then uses internally to convert text to vectors during `add`/`upsert`/`query`.")
    report_lines.append("- **Data Operations:**")
    report_lines.append("  - `KnowledgeStorage`: Uses `collection.upsert(documents=List[str], metadatas=List[Optional[Dict]], ids=List[str])`. IDs are content hashes.")
    report_lines.append("  - `RAGStorage`: Uses `collection.add(documents=[text], metadatas=[metadata], ids=[uuid_str])`. IDs are random UUIDs.")
    report_lines.append("- **Querying:** `collection.query(query_texts=Union[str, List[str]], n_results=int, where=Optional[Dict])`. The `where` clause allows metadata-based filtering.")
    report_lines.append("- **Management:** `app.reset()` for clearing storage.\n")

    report_lines.append("### 1.2. Mapping to User's `Database` Class & Identified Gaps")
    report_lines.append("The user's `Database` class provides methods like `store_embedding(item_id, agent_id, role, content, embedding)` and `retrieve_similar_items(query_embedding, top_k)`. Key differences and gaps when mapping to `crewai`'s needs:")
    report_lines.append("1.  **Embedding Generation:** User's class expects pre-computed embeddings. `crewai` (with `chromadb`) relies on the `embedding_function` within `chromadb` to do this. **Solution:** The new adapter must explicitly generate embeddings before calling the user's `store_embedding` or `retrieve_similar_items` (for query texts).")
    report_lines.append("2.  **Collection Management:** User's class has a single 'memory' table. `crewai` uses named collections. **Solution:** The user's `Database` class needs to be modified or wrapped to handle multiple tables (one per `crewai` collection) or use a single table with a `collection_name` column for differentiation.")
    report_lines.append("3.  **Metadata Storage:** User's `store_embedding` has fixed `agent_id`, `role` fields. `crewai` uses a flexible `metadata` dictionary. **Solution:** User's table schema needs a TEXT column (e.g., `metadata_json`) to store the JSON string of `crewai`'s metadata dictionary.")
    report_lines.append("4.  **Query Filtering (`where` clause):** User's `retrieve_similar_items` does not support metadata filtering. This is a CRITICAL feature for effective RAG. **Solution:** The `retrieve_similar_items` method in the user's `Database` class needs significant enhancement to parse a filter dictionary and construct dynamic SQL `WHERE` clauses (potentially using SQLite's `json_extract` for the `metadata_json` column).")
    report_lines.append("5.  **Search Scalability & Performance:** User's current similarity search loads all embeddings and computes similarity in Python. This will be slow for large datasets. `chromadb` uses indexed vector search (e.g., HNSW). **Note:** This is an inherent performance difference. The SQLite solution will be less performant for large N. Consider this a known trade-off for Termux compatibility with smaller datasets.")
    report_lines.append("6.  **Query Input:** `KnowledgeStorage.search` can take a list of query texts. User's `retrieve_similar_items` takes a single query embedding. **Solution:** The adapter should loop if multiple query texts are provided.\n")

    report_lines.append("### 1.3. Proposed Integration Strategy: Abstract `VectorStoreInterface`")
    report_lines.append("To integrate the SQLite solution cleanly, `crewai` should use an abstraction layer for vector storage.")
    report_lines.append("1.  **Define `VectorStoreInterface` (ABC):**")
    report_lines.append("    ```python")
    report_lines.append("    from abc import ABC, abstractmethod")
    report_lines.append("    from typing import List, Dict, Any, Optional, Union")
    report_lines.append("")
    report_lines.append("    class VectorStoreQueryResult: # Define structure for query results")
    report_lines.append("        # Example attributes, adjust as per actual chromadb query results structure")
    report_lines.append("        # ids: List[str]")
    report_lines.append("        # documents: Optional[List[Optional[str]]]")
    report_lines.append("        # metadatas: Optional[List[Optional[Dict[str, Any]]]]")
    report_lines.append("        # distances: Optional[List[Optional[float]]]")
    report_lines.append("        # Usually, chromadb returns lists of lists for these if multiple queries are made.")
    report_lines.append("        # For a single query's results, it might be List[Dict] or similar.")
    report_lines.append("        # For this interface, let's assume a simplified result per queried item for now.")
    report_lines.append("        id: str")
    report_lines.append("        document: Optional[str] # Changed from context for clarity")
    report_lines.append("        metadata: Optional[Dict[str, Any]]")
    report_lines.append("        distance: Optional[float] # Changed from score for clarity (lower is better)")
    report_lines.append("")
    report_lines.append("        def __init__(self, id: str, document: Optional[str], metadata: Optional[Dict[str, Any]], distance: Optional[float]):")
    report_lines.append("            self.id = id")
    report_lines.append("            self.document = document")
    report_lines.append("            self.metadata = metadata")
    report_lines.append("            self.distance = distance")
    report_lines.append("")
    report_lines.append("    class VectorStoreInterface(ABC):")
    report_lines.append("        @abstractmethod")
    report_lines.append("        def __init__(self, collection_name: str, embedder_config: Optional[Dict[str, Any]] = None, persist_path: Optional[str] = None, **kwargs):")
    report_lines.append("            # self.embedding_model = EmbeddingConfigurator().configure_embedder(embedder_config) # This line needs careful thought")
    report_lines.append("            # EmbeddingConfigurator returns an EmbeddingFunction for Chroma, not a raw model.")
    report_lines.append("            # The interface might need direct access to an embedding generation function/method.")
    report_lines.append("            pass")
    report_lines.append("")
    report_lines.append("        @abstractmethod")
    report_lines.append("        def add(self, documents: List[str], metadatas: Optional[List[Optional[Dict[str, Any]]]] = None, ids: Optional[List[str]] = None) -> None:")
    report_lines.append("            pass")
    report_lines.append("")
    report_lines.append("        @abstractmethod")
    report_lines.append("        def search(self, query_texts: List[str], n_results: int = 5, filter_criteria: Optional[Dict[str, Any]] = None) -> List[List[VectorStoreQueryResult]]:")
    report_lines.append("            # Returns a list of lists, one inner list per query_text")
    report_lines.append("            pass")
    report_lines.append("")
    report_lines.append("        @abstractmethod")
    report_lines.append("        def reset(self) -> None:")
    report_lines.append("            pass")
    report_lines.append("    ```")
    report_lines.append("2.  **Refactor `KnowledgeStorage` & `RAGStorage`:** Modify them to accept and use an instance of `VectorStoreInterface` via dependency injection.")
    report_lines.append("3.  **Create `ChromaDBVectorStore(VectorStoreInterface)`:** Adapts existing `chromadb` logic to this interface. It will manage its own `chromadb.PersistentClient` and `EmbeddingFunction` (via `EmbeddingConfigurator`).")
    report_lines.append("4.  **Create `SQLiteVectorStore(VectorStoreInterface)`:**")
    report_lines.append("    - Wraps the user's (enhanced) `Database` class.")
    report_lines.append("    - **Initialization:** Takes `collection_name` (becomes table name), `embedder_config` (to get an embedding model for explicit embedding generation, likely from `EmbeddingConfigurator` which needs adjustment to provide a direct embedding function).")
    report_lines.append("    - **`add` method:**")
    report_lines.append("        1. Uses an embedding model (derived from `embedder_config`) to get embeddings for input `documents`.")
    report_lines.append("        2. Calls user's `Database.store_embedding` (enhanced for table name and full metadata JSON).")
    report_lines.append("    - **`search` method:**")
    report_lines.append("        1. Uses the embedding model to get embeddings for input `query_texts`.")
    report_lines.append("        2. Calls user's `Database.retrieve_similar_items` (enhanced for table name and metadata filtering).")
    report_lines.append("        3. Formats results to `List[List[VectorStoreQueryResult]]`.")
    report_lines.append("5.  **Enhance User's `Database` Class:**")
    report_lines.append("    - Modify `__init__` to accept `db_path` and `table_name`. Ensure the table exists with schema: `item_id TEXT PRIMARY KEY, content TEXT, embedding BLOB, metadata_json TEXT`.")
    report_lines.append("    - Modify `store_embedding` to use `table_name` and accept `metadata: Dict[str, Any]` (serialize to JSON). Implement `UPSERT` logic using `item_id`.")
    report_lines.append("    - CRITICAL: Modify `retrieve_similar_items` to use `table_name` and accept `filter_criteria: Dict[str, Any]`. Implement dynamic SQL `WHERE` clause generation using SQLite's `json_extract` on `metadata_json` column. For example: `SELECT item_id, content, metadata_json, embedding FROM {table_name} WHERE json_extract(metadata_json, '$.source') = ?`.")
    report_lines.append("6.  **Configuration Update:** `crewai`'s main configuration (e.g., in `Crew` or `KnowledgeBase`) needs to allow specifying the vector store implementation and its specific configuration (like `db_path` for SQLite, `persist_path` for ChromaDB).")
    report_lines.append("    - `EmbeddingConfigurator` will need to be adaptable to provide either a `chromadb.EmbeddingFunction` or a more direct embedding generation callable for the SQLite adapter.\n")

    # --- Section 2: Addressing ONNXRuntime ---
    report_lines.append("## 2. Addressing `onnxruntime` Dependency\n")
    report_lines.append("- **Status:** `onnxruntime` is a core dependency in `crewai`'s `pyproject.toml` but is unavailable in the user's Termux environment.")
    report_lines.append("- **Observation:** No direct Python imports of `onnxruntime` were found in `src/crewai`. This suggests indirect usage (e.g., by a dependency of `crewai` like `tokenizers` or `litellm` under certain configurations) or dynamic loading.")
    report_lines.append("- **Challenge:** Without knowing how/where `crewai`'s functionality might trigger `onnxruntime` (possibly through `litellm` for specific embedding models or local model inference), pinpointing exact refactoring points is difficult.")
    report_lines.append("- **Recommendations:**")
    report_lines.append("  1.  **Audit Usage:** `crewai` maintainers or the user should investigate why `onnxruntime` is a core dependency. Is it tied to specific embedding models in `litellm` or other features? `litellm` documentation mentions ONNX for certain local embedding models.")
    report_lines.append("  2.  **Conditional Logic for Features:** If `onnxruntime` is used for specific, non-default features (e.g., certain local embedding models), ensure these features are wrapped in `try-except ImportError` blocks within `crewai` or its dependencies (like `EmbeddingConfigurator` if it tries to load an ONNX-based embedder).")
    report_lines.append("  3.  **Graceful Degradation:** If `onnxruntime` is not found, affected features should be disabled, and the user should be informed (e.g., warning log, or functions returning a specific status indicating unavailability). For instance, if an ONNX-based embedder fails to load, `EmbeddingConfigurator` should fall back to another available model or raise a clear error.")
    report_lines.append("  4.  **Reclassify Dependency (if applicable):** If `onnxruntime` is only for optional features (e.g., specific local embedding models not used by default), `crewai` maintainers could consider moving it to an optional dependency group (e.g., `crewai[onnx-embeddings]`). This seems like the most viable path if its usage is confirmed to be optional.")
    report_lines.append("  5.  **User Action:** The user should ensure their `litellm` configuration (if they customize it for `crewai`) does not select embedding models or features that require `onnxruntime` if they cannot install it.\n")

    report_lines.append("## 3. Next Steps\n")
    report_lines.append("### For User:")
    report_lines.append("1.  **Enhance `Database` Class:** Implement the changes detailed in section 1.3 (Point 5), focusing on table creation with the new schema, `UPSERT` for `store_embedding`, and robust metadata filtering in `retrieve_similar_items` using `json_extract`.")
    report_lines.append("2.  **Test `Database` Class:** Thoroughly test the enhanced `Database` class standalone with sample data and queries, especially the metadata filtering.\n")
    report_lines.append("### For `crewai` (or User's Fork thereof):")
    report_lines.append("1.  **Implement `VectorStoreInterface`:** Define the ABC as proposed in section 1.3 (Point 1).")
    report_lines.append("2.  **Create `ChromaDBVectorStore` Adapter:** Wrap existing `chromadb` usage into this new interface (section 1.3, Point 3).")
    report_lines.append("3.  **Create `SQLiteVectorStore` Adapter:** Implement this adapter to use the user's enhanced `Database` class and a direct embedding generation mechanism (section 1.3, Point 4). This will involve adjusting `EmbeddingConfigurator` to provide a callable for direct embedding generation if it doesn't already.")
    report_lines.append("4.  **Refactor Storage Classes:** Modify `KnowledgeStorage` and `RAGStorage` to use `VectorStoreInterface` through dependency injection.")
    report_lines.append("5.  **Configuration Mechanism:** Implement a way for `crewai` to select and configure the desired `VectorStoreInterface` implementation at runtime (e.g., based on a config object passed to `Crew` or `KnowledgeBase`).")
    report_lines.append("6.  **Investigate `onnxruntime`:** Determine its exact role. If confirmed optional or for specific embedders, move to an optional dependency group in `pyproject.toml` and ensure `EmbeddingConfigurator` handles its absence gracefully.")
    report_lines.append("7.  **Testing:** Add unit and integration tests for the new interface, both adapters, and the refactored storage classes.\n")

    with open("crewai_sqlite_integration_plan.md", "w", encoding="utf-8") as f:
        f.write("\n".join(report_lines))

    return "Successfully generated crewai_sqlite_integration_plan.md"

if __name__ == "__main__":
    report_status = generate_integration_plan_report()
    print(report_status)
